{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import librosa, os\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from IPython.display import Audio\n",
    "\n",
    "from sys import getsizeof\n",
    "from glob import glob1\n",
    "from numpy import ndarray\n",
    "from keras.utils import Sequence\n",
    "\n",
    "from utils import complex_to_polar, polar_to_complex\n",
    "\n",
    "class PredGenerator(Sequence) : \n",
    "    def __init__(\n",
    "            self, model_input_shape : tuple, src_path : str, pred_dir : str, pattern : str=\".mp3\",\n",
    "            max_cache_size : float=2, restrict_cache=False,\n",
    "            n_fft : int=1918, win_length : int=1024, \n",
    "    ) :\n",
    "        if pattern[0] != \"*\" : pattern = \"*\" + pattern\n",
    "\n",
    "        input_name_list = glob1(dirname=src_path, pattern=pattern)\n",
    "        assert len(input_name_list), AssertionError(\"In src_path, no match with pattern [{}]\".format(pattern))\n",
    "\n",
    "        def sort_and_estimate(name_list) :\n",
    "            # path, name, duration\n",
    "            var_list = [[src_path + name, name, librosa.get_duration(path=src_path + name)] for name in name_list]\n",
    "            var_list = sorted(var_list, key=lambda x : x[2], reverse=True)\n",
    "            path_list = [var[0] for var in var_list]\n",
    "            name_list = [var[1] for var in var_list]\n",
    "            dur_list = [var[2] for var in var_list]\n",
    "            return path_list, name_list, dur_list\n",
    "\n",
    "        self._input_path_list, self._name_list, self._input_dur_list = sort_and_estimate(input_name_list)\n",
    "        self._pred_dir = pred_dir if pred_dir[-1] == \"/\" else pred_dir + \"/\"\n",
    "\n",
    "        if model_input_shape[0] == None : model_input_shape = model_input_shape[1:]\n",
    "        \n",
    "        self._sample_arr = np.zeros(model_input_shape, dtype=np.float32)\n",
    "        self._sample_src = librosa.istft(np.zeros(model_input_shape[:-1], dtype=np.float32), n_fft=n_fft, win_length=win_length)\n",
    "\n",
    "        def estimate_tot_dur(path_list, sample_src) : \n",
    "            sample_dur_list = []\n",
    "            tot_dur_list = []\n",
    "            length_list = []\n",
    "            for path in path_list : \n",
    "                sample_rate = librosa.get_samplerate(path)\n",
    "                sample_dur = librosa.get_duration(y=sample_src, sr=sample_rate)\n",
    "                tot_dur = librosa.get_duration(path=path)\n",
    "                quotient = int(tot_dur // sample_dur) + 1\n",
    "\n",
    "                sample_dur_list.append(sample_dur)\n",
    "                tot_dur_list.append(quotient * sample_dur)\n",
    "                length_list.append(quotient)\n",
    "            return sample_dur_list, tot_dur_list, length_list\n",
    "\n",
    "        self._sample_dur_list, self._tot_dur_list, self._tot_len_list = estimate_tot_dur(self._input_path_list, self._sample_src)\n",
    "        self._offset_list = np.zeros_like(self._sample_dur_list, dtype=np.float32)\n",
    "        self._tot_len = np.sum(self._tot_len_list, dtype=int)\n",
    "        self._src_index = 0\n",
    "\n",
    "        self._n_fft = n_fft\n",
    "        self._win_length = win_length\n",
    "\n",
    "        self._max_cache_size = max_cache_size * (1024**3)\n",
    "        self._restrict_cache = restrict_cache\n",
    "\n",
    "        self._prevent_update_step = 3\n",
    "        self._count = 0\n",
    "        self.X = self._load_data_via_index(update=False)\n",
    "        self._output = np.zeros_like(self.X, dtype=np.float32)\n",
    "\n",
    "    def _estimate_cache(arr_batch) : \n",
    "        pass\n",
    "        # return getsizeof() *\n",
    "\n",
    "    def refresh(self) : \n",
    "        del self.X, self._output\n",
    "        self._count = 0\n",
    "        self.X = self._load_data_via_index(update=False)\n",
    "        self._output = np.zeros_like(self.X, dtype=np.float32)\n",
    "    \n",
    "    def _resource_validation(self, arr : ndarray) : \n",
    "        if arr.shape != self._sample_arr.shape : \n",
    "            temp_arr = np.zeros_like(self._sample_arr)\n",
    "            temp_arr[:,:len(arr[0])] = arr\n",
    "            return temp_arr\n",
    "        else : return arr\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._tot_len\n",
    "    \n",
    "    def __getitem__(self, index) :\n",
    "        return self._load_data_via_index()\n",
    "    \n",
    "    def _load_data(self, src_index, update=True) : \n",
    "        path = self._input_path_list[src_index]\n",
    "        sample_rate = librosa.get_samplerate(path)\n",
    "        sample_dur = self._sample_dur_list[src_index]\n",
    "        src_offset = self._offset_list[src_index]\n",
    "        \n",
    "        source = librosa.load(path, sr=sample_rate, offset=src_offset, duration=sample_dur)[0]\n",
    "        D = librosa.stft(source, n_fft=self._n_fft, win_length=self._win_length)\n",
    "        D = complex_to_polar(D)\n",
    "        D = self._resource_validation(D)\n",
    "        D = np.array([D])\n",
    "        \n",
    "        del source\n",
    "\n",
    "        if update and (self._count < self._prevent_update_step) : self._count += 1\n",
    "        elif update : \n",
    "            self._offset_list[src_index] += sample_dur\n",
    "            self._output = np.hstack((self._output, D))\n",
    "\n",
    "        return D\n",
    "    \n",
    "    def _load_data_via_index(self, update=True) :\n",
    "        index = self._src_index\n",
    "        sample_dur = self._sample_dur_list[index]\n",
    "        src_offset = self._offset_list[index]\n",
    "\n",
    "        return self._load_data(self._src_index, update)\n",
    "    \n",
    "    def on_epoch_end(self) :\n",
    "        index = self._src_index\n",
    "        sample_rate = librosa.get_samplerate(self._input_path_list[index])\n",
    "        pred_dir = self._pred_dir\n",
    "        music_name = self._name_list[index] if music_name[0] != \"/\" else self._name_list[index][1:]\n",
    "\n",
    "        output = polar_to_complex(self._output)\n",
    "        output = librosa.istft(output, n_fft=self._n_fft, win_length=self._win_length)\n",
    "        output = Audio(output, rate=sample_rate)\n",
    "\n",
    "        if os.path.isfile(pred_dir + \"Pred_\" + music_name[:-4] + \".wav\") : \n",
    "            raise AssertionError(\"File already exists in [{}]\".format(pred_dir))\n",
    "\n",
    "        with open(file=pred_dir + \"Pred_\" + music_name[:-4] + \".wav\", mode=\"wb\") as f : \n",
    "            f.write(output)\n",
    "\n",
    "        self._src_index += 1\n",
    "        self._src_index %= len(self._input_path_list)\n",
    "\n",
    "        self.refresh()\n",
    "    \n",
    "    \n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n",
      "(None, 960, 832, 2) [(None, 960, 832, 2), (None, 960, 832, 2)]\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model_path = \"./U_Net_checkpoint/checkpoint.h5\"\n",
    "temp_model = load_model(model_path)\n",
    "print(temp_model.input_shape, temp_model.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 405.21142857142854\n"
     ]
    }
   ],
   "source": [
    "temp_path1 = \"../Data/music/music_only/sample/\"\n",
    "temp_path2 = \"../Data/music/music_only/pred_sample/\"\n",
    "temp_gen = PredGenerator(temp_model.input_shape, src_path=temp_path1, pred_dir=temp_path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../Data/music/music_only/sample/sb_adriftamonginfinitestars.mp3']\n",
      "['sb_adriftamonginfinitestars.mp3']\n"
     ]
    }
   ],
   "source": [
    "print(temp_gen._input_path_list)\n",
    "print(temp_gen._name_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sb_adriftamonginfinitestars'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_gen._name_list[0][:-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84\n",
      "[84]\n"
     ]
    }
   ],
   "source": [
    "print(temp_gen.__len__())\n",
    "print(temp_gen._tot_len_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 405.21142857142854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-21 18:50:20.567769: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 405.21142857142854\n",
      "0.0 405.21142857142854\n",
      " 1/84 [..............................] - ETA: 54s0.0 405.21142857142854\n",
      " 3/84 [>.............................] - ETA: 9s 4.8239455 405.21142857142854\n",
      " 4/84 [>.............................] - ETA: 11s9.647891 405.21142857142854\n",
      " 5/84 [>.............................] - ETA: 12s14.471837 405.21142857142854\n",
      " 6/84 [=>............................] - ETA: 13s19.295782 405.21142857142854\n",
      " 7/84 [=>............................] - ETA: 13s24.119728 405.21142857142854\n",
      " 8/84 [=>............................] - ETA: 13s28.943674 405.21142857142854\n",
      " 9/84 [==>...........................] - ETA: 13s33.76762 405.21142857142854\n",
      "10/84 [==>...........................] - ETA: 13s38.591564 405.21142857142854\n",
      "11/84 [==>...........................] - ETA: 13s43.41551 405.21142857142854\n",
      "12/84 [===>..........................] - ETA: 13s48.239452 405.21142857142854\n",
      "13/84 [===>..........................] - ETA: 13s53.063396 405.21142857142854\n",
      "14/84 [====>.........................] - ETA: 13s57.88734 405.21142857142854\n",
      "15/84 [====>.........................] - ETA: 12s62.711285 405.21142857142854\n",
      "16/84 [====>.........................] - ETA: 12s67.53523 405.21142857142854\n",
      "17/84 [=====>........................] - ETA: 12s72.35918 405.21142857142854\n",
      "18/84 [=====>........................] - ETA: 12s77.18312 405.21142857142854\n",
      "19/84 [=====>........................] - ETA: 12s82.007065 405.21142857142854\n",
      "20/84 [======>.......................] - ETA: 12s86.83101 405.21142857142854\n",
      "21/84 [======>.......................] - ETA: 12s91.65495 405.21142857142854\n",
      "22/84 [======>.......................] - ETA: 11s96.4789 405.21142857142854\n",
      "23/84 [=======>......................] - ETA: 11s101.30284 405.21142857142854\n",
      "24/84 [=======>......................] - ETA: 11s106.126785 405.21142857142854\n",
      "25/84 [=======>......................] - ETA: 11s110.95073 405.21142857142854\n",
      "26/84 [========>.....................] - ETA: 11s115.77467 405.21142857142854\n",
      "27/84 [========>.....................] - ETA: 11s120.59862 405.21142857142854\n",
      "28/84 [=========>....................] - ETA: 10s125.42256 405.21142857142854\n",
      "29/84 [=========>....................] - ETA: 10s130.2465 405.21142857142854\n",
      "30/84 [=========>....................] - ETA: 10s135.07045 405.21142857142854\n",
      "31/84 [==========>...................] - ETA: 10s139.8944 405.21142857142854\n",
      "32/84 [==========>...................] - ETA: 10s144.71834 405.21142857142854\n",
      "33/84 [==========>...................] - ETA: 9s 149.54228 405.21142857142854\n",
      "34/84 [===========>..................] - ETA: 9s154.36623 405.21142857142854\n",
      "35/84 [===========>..................] - ETA: 9s159.19017 405.21142857142854\n",
      "36/84 [===========>..................] - ETA: 9s164.01411 405.21142857142854\n",
      "37/84 [============>.................] - ETA: 9s168.83806 405.21142857142854\n",
      "38/84 [============>.................] - ETA: 9s173.662 405.21142857142854\n",
      "39/84 [============>.................] - ETA: 8s178.48595 405.21142857142854\n",
      "40/84 [=============>................] - ETA: 8s183.30989 405.21142857142854\n",
      "41/84 [=============>................] - ETA: 8s188.13383 405.21142857142854\n",
      "42/84 [==============>...............] - ETA: 8s192.95778 405.21142857142854\n",
      "43/84 [==============>...............] - ETA: 8s197.78172 405.21142857142854\n",
      "44/84 [==============>...............] - ETA: 7s202.60567 405.21142857142854\n",
      "45/84 [===============>..............] - ETA: 7s207.42961 405.21142857142854\n",
      "46/84 [===============>..............] - ETA: 7s212.25356 405.21142857142854\n",
      "47/84 [===============>..............] - ETA: 7s217.0775 405.21142857142854\n",
      "48/84 [================>.............] - ETA: 7s221.90144 405.21142857142854\n",
      "49/84 [================>.............] - ETA: 6s226.72539 405.21142857142854\n",
      "50/84 [================>.............] - ETA: 6s231.54933 405.21142857142854\n",
      "51/84 [=================>............] - ETA: 6s236.37328 405.21142857142854\n",
      "52/84 [=================>............] - ETA: 6s241.19722 405.21142857142854\n",
      "53/84 [=================>............] - ETA: 6s246.02116 405.21142857142854\n",
      "54/84 [==================>...........] - ETA: 5s250.84511 405.21142857142854\n",
      "55/84 [==================>...........] - ETA: 5s255.66905 405.21142857142854\n",
      "56/84 [===================>..........] - ETA: 5s260.493 405.21142857142854\n",
      "57/84 [===================>..........] - ETA: 5s265.31696 405.21142857142854\n",
      "58/84 [===================>..........] - ETA: 5s270.1409 405.21142857142854\n",
      "59/84 [====================>.........] - ETA: 4s274.96484 405.21142857142854\n",
      "279.7888 405.21142857142854\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m Model\n\u001b[1;32m      3\u001b[0m Model\u001b[39m.\u001b[39mpredict_generator\n\u001b[0;32m----> 4\u001b[0m temp_ouput \u001b[39m=\u001b[39m temp_model\u001b[39m.\u001b[39;49mpredict(x\u001b[39m=\u001b[39;49mtemp_gen)\n",
      "File \u001b[0;32m~/miniforge3/envs/tf_env/lib/python3.9/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniforge3/envs/tf_env/lib/python3.9/site-packages/keras/engine/training.py:2382\u001b[0m, in \u001b[0;36mModel.predict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   2380\u001b[0m \u001b[39mfor\u001b[39;00m step \u001b[39min\u001b[39;00m data_handler\u001b[39m.\u001b[39msteps():\n\u001b[1;32m   2381\u001b[0m     callbacks\u001b[39m.\u001b[39mon_predict_batch_begin(step)\n\u001b[0;32m-> 2382\u001b[0m     tmp_batch_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict_function(iterator)\n\u001b[1;32m   2383\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   2384\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniforge3/envs/tf_env/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniforge3/envs/tf_env/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:894\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    891\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    893\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 894\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    896\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    897\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniforge3/envs/tf_env/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:933\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    930\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    931\u001b[0m \u001b[39m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    932\u001b[0m \u001b[39m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 933\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    934\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_created_variables \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001b[1;32m    935\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCreating variables on a non-first call to a function\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    936\u001b[0m                    \u001b[39m\"\u001b[39m\u001b[39m decorated with tf.function.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/envs/tf_env/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:143\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    141\u001b[0m   (concrete_function,\n\u001b[1;32m    142\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m    144\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/miniforge3/envs/tf_env/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1757\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1753\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1754\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1755\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1756\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1757\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1758\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1759\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1760\u001b[0m     args,\n\u001b[1;32m   1761\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1762\u001b[0m     executing_eagerly)\n\u001b[1;32m   1763\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniforge3/envs/tf_env/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:381\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    380\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 381\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    382\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    383\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    384\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    385\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    386\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    387\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    388\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    389\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    390\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    393\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    394\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/miniforge3/envs/tf_env/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras import Model\n",
    "\n",
    "Model.predict_generator\n",
    "temp_ouput = temp_model.predict(x=temp_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(temp_ouput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(84, 960, 832, 2)\n",
      "(84, 960, 832, 2)\n"
     ]
    }
   ],
   "source": [
    "print(temp_ouput[0].shape)\n",
    "print(temp_ouput[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generates output predictions for the input samples.\n",
      "\n",
      "        Computation is done in batches. This method is designed for batch\n",
      "        processing of large numbers of inputs. It is not intended for use inside\n",
      "        of loops that iterate over your data and process small numbers of inputs\n",
      "        at a time.\n",
      "\n",
      "        For small numbers of inputs that fit in one batch,\n",
      "        directly use `__call__()` for faster execution, e.g.,\n",
      "        `model(x)`, or `model(x, training=False)` if you have layers such as\n",
      "        `tf.keras.layers.BatchNormalization` that behave differently during\n",
      "        inference. You may pair the individual model call with a `tf.function`\n",
      "        for additional performance inside your inner loop.\n",
      "        If you need access to numpy array values instead of tensors after your\n",
      "        model call, you can use `tensor.numpy()` to get the numpy array value of\n",
      "        an eager tensor.\n",
      "\n",
      "        Also, note the fact that test loss is not affected by\n",
      "        regularization layers like noise and dropout.\n",
      "\n",
      "        Note: See [this FAQ entry](\n",
      "        https://keras.io/getting_started/faq/#whats-the-difference-between-model-methods-predict-and-call)\n",
      "        for more details about the difference between `Model` methods\n",
      "        `predict()` and `__call__()`.\n",
      "\n",
      "        Args:\n",
      "            x: Input samples. It could be:\n",
      "              - A Numpy array (or array-like), or a list of arrays\n",
      "                (in case the model has multiple inputs).\n",
      "              - A TensorFlow tensor, or a list of tensors\n",
      "                (in case the model has multiple inputs).\n",
      "              - A `tf.data` dataset.\n",
      "              - A generator or `keras.utils.Sequence` instance.\n",
      "              A more detailed description of unpacking behavior for iterator\n",
      "              types (Dataset, generator, Sequence) is given in the `Unpacking\n",
      "              behavior for iterator-like inputs` section of `Model.fit`.\n",
      "            batch_size: Integer or `None`.\n",
      "                Number of samples per batch.\n",
      "                If unspecified, `batch_size` will default to 32.\n",
      "                Do not specify the `batch_size` if your data is in the\n",
      "                form of dataset, generators, or `keras.utils.Sequence` instances\n",
      "                (since they generate batches).\n",
      "            verbose: `\"auto\"`, 0, 1, or 2. Verbosity mode.\n",
      "                0 = silent, 1 = progress bar, 2 = single line.\n",
      "                `\"auto\"` defaults to 1 for most cases, and to 2 when used with\n",
      "                `ParameterServerStrategy`. Note that the progress bar is not\n",
      "                particularly useful when logged to a file, so `verbose=2` is\n",
      "                recommended when not running interactively (e.g. in a production\n",
      "                environment).\n",
      "            steps: Total number of steps (batches of samples)\n",
      "                before declaring the prediction round finished.\n",
      "                Ignored with the default value of `None`. If x is a `tf.data`\n",
      "                dataset and `steps` is None, `predict()` will\n",
      "                run until the input dataset is exhausted.\n",
      "            callbacks: List of `keras.callbacks.Callback` instances.\n",
      "                List of callbacks to apply during prediction.\n",
      "                See [callbacks](\n",
      "                https://www.tensorflow.org/api_docs/python/tf/keras/callbacks).\n",
      "            max_queue_size: Integer. Used for generator or\n",
      "                `keras.utils.Sequence` input only. Maximum size for the\n",
      "                generator queue. If unspecified, `max_queue_size` will default\n",
      "                to 10.\n",
      "            workers: Integer. Used for generator or `keras.utils.Sequence` input\n",
      "                only. Maximum number of processes to spin up when using\n",
      "                process-based threading. If unspecified, `workers` will default\n",
      "                to 1.\n",
      "            use_multiprocessing: Boolean. Used for generator or\n",
      "                `keras.utils.Sequence` input only. If `True`, use process-based\n",
      "                threading. If unspecified, `use_multiprocessing` will default to\n",
      "                `False`. Note that because this implementation relies on\n",
      "                multiprocessing, you should not pass non-picklable arguments to\n",
      "                the generator as they can't be passed easily to children\n",
      "                processes.\n",
      "\n",
      "        See the discussion of `Unpacking behavior for iterator-like inputs` for\n",
      "        `Model.fit`. Note that Model.predict uses the same interpretation rules\n",
      "        as `Model.fit` and `Model.evaluate`, so inputs must be unambiguous for\n",
      "        all three methods.\n",
      "\n",
      "        Returns:\n",
      "            Numpy array(s) of predictions.\n",
      "\n",
      "        Raises:\n",
      "            RuntimeError: If `model.predict` is wrapped in a `tf.function`.\n",
      "            ValueError: In case of mismatch between the provided\n",
      "                input data and the model's expectations,\n",
      "                or in case a stateful model receives a number of samples\n",
      "                that is not a multiple of the batch size.\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "from keras import Model\n",
    "\n",
    "print(Model.predict.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BCE\n",
      "BinaryCrossentropy\n",
      "BinaryFocalCrossentropy\n",
      "CategoricalCrossentropy\n",
      "CategoricalHinge\n",
      "CosineSimilarity\n",
      "Hinge\n",
      "Huber\n",
      "KLD\n",
      "KLDivergence\n",
      "LABEL_DTYPES_FOR_LOSSES\n",
      "LogCosh\n",
      "Loss\n",
      "LossFunctionWrapper\n",
      "MAE\n",
      "MAPE\n",
      "MSE\n",
      "MSLE\n",
      "MeanAbsoluteError\n",
      "MeanAbsolutePercentageError\n",
      "MeanSquaredError\n",
      "MeanSquaredLogarithmicError\n",
      "Poisson\n",
      "SparseCategoricalCrossentropy\n",
      "SquaredHinge\n",
      "__builtins__\n",
      "__cached__\n",
      "__doc__\n",
      "__file__\n",
      "__loader__\n",
      "__name__\n",
      "__package__\n",
      "__spec__\n",
      "_maybe_convert_labels\n",
      "_ragged_tensor_apply_loss\n",
      "_ragged_tensor_binary_crossentropy\n",
      "_ragged_tensor_binary_focal_crossentropy\n",
      "_ragged_tensor_categorical_crossentropy\n",
      "_ragged_tensor_mae\n",
      "_ragged_tensor_mape\n",
      "_ragged_tensor_mse\n",
      "_ragged_tensor_msle\n",
      "_ragged_tensor_sparse_categorical_crossentropy\n",
      "abc\n",
      "backend\n",
      "bce\n",
      "binary_crossentropy\n",
      "binary_focal_crossentropy\n",
      "categorical_crossentropy\n",
      "categorical_hinge\n",
      "cosine_similarity\n",
      "deserialize\n",
      "deserialize_keras_object\n",
      "dispatch\n",
      "doc_controls\n",
      "functools\n",
      "get\n",
      "hinge\n",
      "huber\n",
      "huber_loss\n",
      "is_categorical_crossentropy\n",
      "keras_export\n",
      "kl_divergence\n",
      "kld\n",
      "kullback_leibler_divergence\n",
      "legacy_serialization\n",
      "log_cosh\n",
      "logcosh\n",
      "losses_utils\n",
      "mae\n",
      "mape\n",
      "mean_absolute_error\n",
      "mean_absolute_percentage_error\n",
      "mean_squared_error\n",
      "mean_squared_logarithmic_error\n",
      "mse\n",
      "msle\n",
      "poisson\n",
      "ragged_map_ops\n",
      "ragged_util\n",
      "saving_lib\n",
      "serialize\n",
      "serialize_keras_object\n",
      "sparse_categorical_crossentropy\n",
      "squared_hinge\n",
      "tf\n",
      "tf_utils\n",
      "warnings\n"
     ]
    }
   ],
   "source": [
    "from keras import losses\n",
    "\n",
    "for something in dir(losses) : \n",
    "    print(something)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
