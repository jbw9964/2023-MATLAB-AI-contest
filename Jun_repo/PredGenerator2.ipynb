{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import librosa, os\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from IPython.display import Audio\n",
    "\n",
    "from keras import Model\n",
    "from sys import getsizeof\n",
    "from glob import glob1\n",
    "from numpy import ndarray\n",
    "from keras.utils import Sequence\n",
    "\n",
    "from utils import complex_to_polar, polar_to_complex\n",
    "\n",
    "class PredGenerator(Sequence) : \n",
    "    def __init__(\n",
    "            self, model_input_shape : tuple, src_path : str, pred_dir : str, pattern : str=\".mp3\",\n",
    "            n_fft : int=1918, win_length : int=1024, \n",
    "    ) :\n",
    "        if pattern[0] != \"*\" : pattern = \"*\" + pattern\n",
    "\n",
    "        input_name_list = glob1(dirname=src_path, pattern=pattern)\n",
    "        assert len(input_name_list), AssertionError(\"In src_path, no match with pattern [{}]\".format(pattern))\n",
    "\n",
    "        def sort_via_dur(name_list) :\n",
    "            # path, name, duration\n",
    "            var_list = [[src_path + name, name, librosa.get_duration(path=src_path + name)] for name in name_list]\n",
    "            var_list = sorted(var_list, key=lambda x : x[2], reverse=True)\n",
    "            path_list = [var[0] for var in var_list]\n",
    "            name_list = [var[1][:-4] for var in var_list]\n",
    "            dur_list = [var[2] for var in var_list]\n",
    "            return path_list, name_list, dur_list\n",
    "        def solve_path(path) : \n",
    "            if not os.path.exists(path) : os.makedirs(path)\n",
    "\n",
    "        self._input_path_list, self._name_list, self._input_dur_list = sort_via_dur(input_name_list)\n",
    "        self._pred_dir = pred_dir if pred_dir[-1] == \"/\" else pred_dir + \"/\"\n",
    "        solve_path(self._pred_dir)\n",
    "\n",
    "        self._input_shape = model_input_shape[1:] if model_input_shape[0] == None else model_input_shape\n",
    "        self._sample_arr = np.zeros(self._input_shape[:-1], dtype=np.int0)\n",
    "        self._sample_shape = self._sample_arr.shape\n",
    "        self._sample_src = librosa.istft(self._sample_arr, n_fft=n_fft, win_length=win_length)\n",
    "\n",
    "        def estimate_dur(sample_src, path_list) : \n",
    "            sample_dur_list = []\n",
    "            tot_dur_list = []\n",
    "            for path in path_list : \n",
    "                sample_rate = librosa.get_samplerate(path)\n",
    "                sample_dur = librosa.get_duration(y=sample_src, sr=sample_rate)\n",
    "                try : tot_dur = librosa.get_duration(path=path)\n",
    "                except : tot_dur = librosa.get_duration(filename=path)\n",
    "                quotient = tot_dur // sample_dur\n",
    "                tot_dur = (quotient + 1) * sample_dur\n",
    "\n",
    "                sample_dur_list.append(sample_dur)\n",
    "                tot_dur_list.append(tot_dur)\n",
    "\n",
    "            return sample_dur_list, tot_dur_list\n",
    "        \n",
    "        self._sample_dur_list, self._tot_dur_list = estimate_dur(self._sample_src, self._input_path_list)\n",
    "        self._offset_list = np.zeros_like(self._input_path_list, dtype=np.float32)\n",
    "\n",
    "        self._n_fft = n_fft\n",
    "        self._win_len = win_length\n",
    "        \n",
    "        self.src_index = 0\n",
    "        self._output = []\n",
    "        self._is_all_done = False\n",
    "        self._patience = 1\n",
    "        self._count = 0\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(self._tot_dur_list[self.src_index] // self._sample_dur_list[self.src_index]) - 1\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        if self._count < self._patience : \n",
    "            self._count += 1\n",
    "            return self._gen_data(self.src_index, update=False)\n",
    "        return self._gen_data(self.src_index, update=True)\n",
    "    \n",
    "    def before_pred(self) : \n",
    "        path = self._input_path_list[self.src_index]\n",
    "        sample_rate = librosa.get_samplerate(path)\n",
    "        pred_dir = self._pred_dir\n",
    "        if pred_dir[-1] != \"/\" : pred_dir += \"/\"\n",
    "        pred_dir += self._name_list[self.src_index] + \".wav\"\n",
    "        \n",
    "        return sample_rate, pred_dir, self._n_fft, self._win_len, self._sample_shape, self.__len__()\n",
    "\n",
    "    def on_epoch_end(self) :\n",
    "        self.src_index += 1\n",
    "        self._count = 0\n",
    "        if self.src_index >= len(self._input_path_list) : \n",
    "            self._is_all_done = True\n",
    "    \n",
    "    def _resource_validation(self, sample_src : ndarray) : \n",
    "        if self._sample_src.shape != sample_src.shape : \n",
    "            temp_arr = np.zeros_like(self._sample_src)\n",
    "            temp_arr[:len(sample_src)] = sample_src\n",
    "            return temp_arr\n",
    "        else : return sample_src\n",
    "\n",
    "    def _gen_data(self, src_index, update=True) : \n",
    "        path = self._input_path_list[src_index]\n",
    "        sample_rate = librosa.get_samplerate(path)\n",
    "        sample_dur = self._sample_dur_list[src_index]\n",
    "        offset = self._offset_list[src_index]\n",
    "\n",
    "        if offset + sample_dur > self._tot_dur_list[src_index] : \n",
    "            source = librosa.load(path=path, sr=sample_rate, offset=offset)[0]\n",
    "        else : \n",
    "            source = librosa.load(path=path, sr=sample_rate, offset=offset, duration=sample_dur)[0]\n",
    "        source = self._resource_validation(source)\n",
    "        D = librosa.stft(source, n_fft=self._n_fft, win_length=self._win_len)\n",
    "        D = complex_to_polar(D)\n",
    "\n",
    "        if update : self._offset_list[src_index] += sample_dur\n",
    "        del source\n",
    "        return np.array([D])\n",
    "\n",
    "    @property\n",
    "    def input_shape(self) : \n",
    "        return self._input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, sys, gc\n",
    "\n",
    "from threading import Thread\n",
    "from keras import Model\n",
    "\n",
    "def convert_pred(\n",
    "            model : Model, src_path : str, pred_dir : str, pattern : str=\".mp3\",\n",
    "            max_cache_size : float=2, restrict_cache=False,\n",
    "            n_fft : int=1918, win_length : int=1024, \n",
    "    ) : \n",
    "        def check_status() :\n",
    "            nonlocal total_num, count, stdout_list\n",
    "            while count <= total_num : \n",
    "                string = \"\\rProcessing... [{}] : \".format(stdout_list[0]).ljust(15)\n",
    "                string += \"[{}/{}]\".format(str(count).zfill(3), str(total_num).zfill(3))\n",
    "                sys.stdout.write(string)\n",
    "                sys.stdout.flush()\n",
    "                stdout_list.append(stdout_list.pop(0))\n",
    "                time.sleep(0.15)\n",
    "\n",
    "        input_shape = model.input_shape\n",
    "        pred_generator = PredGenerator(input_shape, src_path, pred_dir, pattern, n_fft, win_length)\n",
    "\n",
    "        max_cache_size = max_cache_size * (1024**3)\n",
    "\n",
    "        total_num = len(pred_generator._input_path_list)\n",
    "        count = 1\n",
    "\n",
    "        stdout_list = \"/-\\|\"\n",
    "        stdout_list = list(stdout_list)\n",
    "        t1 = Thread(target=check_status)\n",
    "        t1.start()\n",
    "        while not pred_generator._is_all_done : \n",
    "            # print(count)\n",
    "            sample_rate, pred_path, n_fft, win_len, sample_shape, total_length = pred_generator.before_pred()\n",
    "            pred_data = model.predict(pred_generator, verbose=False)\n",
    "\n",
    "            assert type(pred_data) == ndarray\n",
    "            \n",
    "            total_arr = np.zeros(\n",
    "                (pred_generator.input_shape[0], pred_generator.input_shape[1] * total_length), \n",
    "                dtype=np.complex64\n",
    "            )\n",
    "            \n",
    "            pivot = 0\n",
    "            for bulk_arr in pred_data : \n",
    "                bulk_pivot = 0\n",
    "                bulk_max_pivot = len(bulk_arr[0])\n",
    "                \n",
    "                while bulk_pivot < bulk_max_pivot : \n",
    "                    alter_pivot = 64\n",
    "                    total_arr[:,pivot:pivot + alter_pivot] = polar_to_complex(bulk_arr[:,bulk_pivot:bulk_pivot + alter_pivot])\n",
    "\n",
    "                    bulk_pivot += alter_pivot\n",
    "                    pivot += alter_pivot\n",
    "\n",
    "            output = librosa.istft(total_arr, n_fft=n_fft, win_length=win_len)\n",
    "            output_audio = Audio(output, rate=sample_rate)\n",
    "            with open(pred_path, mode=\"wb\") as f : \n",
    "                f.write(output_audio.data)\n",
    "\n",
    "            del pred_data, total_arr, output, output_audio\n",
    "            gc.collect()\n",
    "            \n",
    "            count += 1\n",
    "        \n",
    "        t1.join()\n",
    "\n",
    "        print(\"\\t Done\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n",
      "(None, 960, 832, 2) (None, 960, 832, 2)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model_path = \"../model_save/checkpoint.h5\"\n",
    "temp_model = load_model(model_path)\n",
    "print(temp_model.input_shape, temp_model.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing... [\\] : [001/002]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-25 18:44:16.345725: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing... [/] : [002/002]\t Done\n"
     ]
    }
   ],
   "source": [
    "music_path = \"../Data/music/pred_sample/music2/\"\n",
    "pred_path = \"../Data/music/pred_sample/pred/\"\n",
    "\n",
    "convert_pred(temp_model, music_path, pred_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_path1 = \"../Data/music/pred_sample/music/\"\n",
    "temp_path2 = \"../Data/music/pred_sample/pred/\"\n",
    "\n",
    "convert_pred(temp_model, temp_path1, temp_path2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
